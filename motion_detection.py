# -*- coding: utf-8 -*-
"""CV_project_approach2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zk4z-uNJmVyvbNOzEYRitKzh1P9OjWrE
"""

import cv2
import numpy as np
import os
from google.colab.patches import cv2_imshow

# Define file locations
input_video = "/content/car video.mp4"
frames_output_path = "/content/output_motion_frames"
os.makedirs(frames_output_path, exist_ok=True)

# Load video
video_capture = cv2.VideoCapture(input_video)

if not video_capture.isOpened():
    print("Error: Cannot access video at:", input_video)
else:
    print("Video file opened successfully.")

# Process the first frame
ret, initial_frame = video_capture.read()
if not ret:
    print("Error: Unable to read the initial frame.")
    video_capture.release()
else:
    previous_gray = cv2.cvtColor(initial_frame, cv2.COLOR_BGR2GRAY)
    counter = 1
    total_saved = 0

    while True:
        ret, current_frame = video_capture.read()
        if not ret:
            break

        if counter % 2 == 0:  # Select every second frame
            gray_current = cv2.cvtColor(current_frame, cv2.COLOR_BGR2GRAY)

            # Compute difference between frames
            frame_difference = cv2.absdiff(previous_gray, gray_current)

            # Threshold to extract moving regions
            _, motion_binary = cv2.threshold(frame_difference, 25, 255, cv2.THRESH_BINARY)

            # Convert to 3-channel image and highlight motion
            motion_colored = cv2.cvtColor(motion_binary, cv2.COLOR_GRAY2BGR)
            motion_colored[motion_binary == 255] = [0, 255, 0]

            # Merge original frame and motion mask
            blended_output = cv2.addWeighted(current_frame, 0.7, motion_colored, 0.3, 0)

            # Save result
            frame_filename = os.path.join(frames_output_path, f"frame_{counter}.jpg")
            cv2.imwrite(frame_filename, blended_output)
            print(f"Saved frame: {frame_filename}")
            total_saved += 1

            if total_saved == 1:
                cv2_imshow(blended_output)

            previous_gray = gray_current.copy()

        counter += 1

    video_capture.release()
    print(f"Processing finished. Total output frames: {total_saved}")

import cv2
import os

# Set directories for frames and output video
frames_directory = "/content/output_motion_frames"
final_video_path = "/content/final_motion_output.mp4"
frame_rate = 10

# Gather image files and sort by frame number
image_files = sorted([f for f in os.listdir(frames_directory) if f.endswith(".jpg")],
                     key=lambda x: int(x.split('_')[1].split('.')[0]))

# Read dimensions from the first frame
first_image_path = os.path.join(frames_directory, image_files[0])
first_image = cv2.imread(first_image_path)
video_height, video_width, _ = first_image.shape

# Configure video writer
video_format = cv2.VideoWriter_fourcc(*'mp4v')
video_writer = cv2.VideoWriter(final_video_path, video_format, frame_rate, (video_width, video_height))

# Write all frames to the video
for image_name in image_files:
    full_path = os.path.join(frames_directory, image_name)
    frame = cv2.imread(full_path)
    video_writer.write(frame)

video_writer.release()
print(f"Final video created at: {final_video_path}")